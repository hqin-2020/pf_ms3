{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db884b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "with open('Run_no_para_update.py') as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0a77341",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['import numpy as np\\n',\n",
       " 'import scipy as sp\\n',\n",
       " 'import pandas as pd\\n',\n",
       " 'import matplotlib.pyplot as plt\\n',\n",
       " 'import seaborn as sns\\n',\n",
       " 'import time\\n',\n",
       " 'from tqdm import tqdm\\n',\n",
       " 'import multiprocessing\\n',\n",
       " 'import pickle\\n',\n",
       " 'import os\\n',\n",
       " '\\n',\n",
       " 'from PF_no_para_update import *\\n',\n",
       " '\\n',\n",
       " \"if __name__ == '__main__':\\n\",\n",
       " '\\n',\n",
       " '    workdir = os.path.dirname(os.getcwd())\\n',\n",
       " '    srcdir = os.getcwd()\\n',\n",
       " \"    datadir = workdir + '/data/'\\n\",\n",
       " \"    outputdir = '/project2/lhansen/pf_ms3/'\\n\",\n",
       " '    seed = 0\\n',\n",
       " '\\n',\n",
       " \"    obs_series = pd.read_csv(datadir + 'data.csv', delimiter=',',header = None)\\n\",\n",
       " '    obs_series = np.array(obs_series)\\n',\n",
       " '\\n',\n",
       " '    T = obs_series.shape[1]\\n',\n",
       " '    N = 10_000\\n',\n",
       " '\\n',\n",
       " \"    case = 'actual data, seed = ' + str(seed) + ', T = ' + str(T) + ', N = ' + str(N)\\n\",\n",
       " '    try: \\n',\n",
       " \"        casedir = outputdir + case  + '/'\\n\",\n",
       " '        os.mkdir(casedir)\\n',\n",
       " '    except:\\n',\n",
       " \"        casedir = outputdir + case  + '/'\\n\",\n",
       " '\\n',\n",
       " '    D_0 = obs_series[:,[0]]\\n',\n",
       " '    Input_0 = [[D_0, seed+i] for i in range(N)]\\n',\n",
       " '    pool = multiprocessing.Pool()\\n',\n",
       " '    X_t_particle = pool.map(init, tqdm(Input_0))\\n',\n",
       " '    del(Input_0)\\n',\n",
       " \"    with open(casedir + 'X_0.pkl', 'wb') as f:\\n\",\n",
       " '        pickle.dump(X_t_particle, f)\\n',\n",
       " '    \\n',\n",
       " '    for t in tqdm(range(T-1)):\\n',\n",
       " '        print(t)\\n',\n",
       " '        D_t_next = obs_series[:,[t+1]]\\n',\n",
       " '        Input = [[D_t_next, X_t_particle[i], seed+t+i] for i in range(N)]\\n',\n",
       " '        del(D_t_next)\\n',\n",
       " '        del(X_t_particle)\\n',\n",
       " '        pool = multiprocessing.Pool()\\n',\n",
       " '        Output = pool.map(recursive, Input)\\n',\n",
       " '        del(Input)\\n',\n",
       " '        X_t_next_particle = [i[0] for i in Output]\\n',\n",
       " '        ν_t_next_particle = [i[1] for i in Output]   \\n',\n",
       " '        del(Output) \\n',\n",
       " \"        with open(casedir + 'X_' + str(t+1) + '.pkl', 'wb') as f:\\n\",\n",
       " '            pickle.dump(X_t_next_particle, f)\\n',\n",
       " '\\n',\n",
       " '        w_t_next = ν_t_next_particle/np.sum(ν_t_next_particle)\\n',\n",
       " '        del(ν_t_next_particle)\\n',\n",
       " '\\n',\n",
       " '        try:\\n',\n",
       " '            count_all = sp.stats.multinomial.rvs(N, w_t_next)\\n',\n",
       " '        except:\\n',\n",
       " '            for i in range(w_t_next.shape[0]):\\n',\n",
       " '                if w_t_next[i]>(np.sum(w_t_next[:-1]) - 1):\\n',\n",
       " '                    w_t_next[i] = w_t_next[i] - (np.sum(w_t_next[:-1]) - 1)\\n',\n",
       " '                    break\\n',\n",
       " '            count_all = sp.stats.multinomial.rvs(N, w_t_next)\\n',\n",
       " '        \\n',\n",
       " \"        with open(casedir + 'w_' + str(t+1) + '.pkl', 'wb') as f:\\n\",\n",
       " '            pickle.dump(w_t_next, f)\\n',\n",
       " '        del(w_t_next)\\n',\n",
       " \"        with open(casedir + 'count_' + str(t+1) + '.pkl', 'wb') as f:\\n\",\n",
       " '            pickle.dump(count_all, f)\\n',\n",
       " '        \\n',\n",
       " '        X_t_particle = []       \\n',\n",
       " '        for i in range(N):\\n',\n",
       " '            if count_all[i] != 0:\\n',\n",
       " '                for n in range(count_all[i]):\\n',\n",
       " '                    X_t_particle.append(X_t_next_particle[i])\\n',\n",
       " '        del(count_all)        \\n',\n",
       " '        del(X_t_next_particle)\\n',\n",
       " '        ']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53de81f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for block in range(1,131):\n",
    "    for i in range(len(lines)):\n",
    "        if lines[i].startswith('    seed = '):\n",
    "            lines[i] = '    seed = '+str(block) + '\\n'\n",
    "    with open('Run_no_para_update_'+str(block)+'.py', 'w') as f:\n",
    "        f.writelines(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bda0481",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2ddbf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
